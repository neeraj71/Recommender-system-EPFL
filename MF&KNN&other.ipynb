{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains test results on three Baseline, MF-ALS, MF-SGD, NNMF and KNN: user-based and item based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from helpers import load_data\n",
    "from utils import split_data\n",
    "\n",
    "from baselines import *\n",
    "from matrix_factorization import matrix_factorization_sgd, write_sgd_prediction, matrix_factorization_als, write_als_prediction\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process data and traform to sparse matrix\n",
    "path_dataset = \"./data/data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original ratings : (10000, 1000)\n",
      "Shape of valid ratings (and of train and test data) : (9990, 999)\n",
      "Total number of nonzero elements in original data : 1176952\n",
      "Total number of nonzero elements in train data : 1068523\n",
      "Total number of nonzero elements in test data : 108350\n"
     ]
    }
   ],
   "source": [
    "#load data and store in pickle \n",
    "_, train, test = split_data(ratings, 10, verbose=True)\n",
    "with open('./data/pickle/train.pickle', 'wb') as file:\n",
    "    pickle.dump(train, file)\n",
    "with open('./data/pickle/test.pickle', 'wb') as file:\n",
    "    pickle.dump(test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+00, 8.40e+01, 4.00e+00],\n",
       "       [1.00e+00, 4.39e+02, 4.00e+00],\n",
       "       [2.00e+00, 4.80e+01, 4.00e+00],\n",
       "       ...,\n",
       "       [9.99e+03, 7.36e+02, 3.00e+00],\n",
       "       [9.99e+03, 9.06e+02, 4.00e+00],\n",
       "       [9.99e+03, 9.85e+02, 1.00e+00]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function change a sparse matrix to a n*3 array\n",
    "# It makes our blending part easy to implement  \n",
    "def toarray(matrix):\n",
    "    nnz_row, nnz_col = matrix.nonzero()\n",
    "    rat = matrix[matrix.nonzero()].toarray().reshape((len(nnz_col),1))\n",
    "    nnz_row += 1\n",
    "    nnz_col += 1\n",
    "    return np.concatenate((nnz_row.reshape(len(nnz_col),1), nnz_col.reshape(len(nnz_col),1), rat), axis=1)\n",
    "\n",
    "test_matrix = toarray(test)\n",
    "test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrameramepandas as pd\n",
    "def savepred(a, name):\n",
    "    a = pd.DataFrame(a)\n",
    "    a.to_csv(\"./data/name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we are going to use global mean, user mean and item mean to test the error of baseline model. It is reasonable that these model do not have good performace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Global Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 25.113199949264526 seconds ---\n",
      "Global mean RMSE : 1.1183506557779523\n"
     ]
    }
   ],
   "source": [
    "#to test the result of global mean\n",
    "start_time = time.time()\n",
    "global_mean_rmse = global_mean_test(ratings, min_num_ratings=10)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('Global mean RMSE : {}'.format(global_mean_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computer a test prediction for blending\n",
    "blend_GlbMean = np.ones((test_matrix.shape[0], 1)) * global_mean(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 User Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 166.68256092071533 seconds ---\n",
      "User mean RMSE : 1.0289888944873853\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "user_mean_rmse = user_mean_test(ratings, min_num_ratings=10)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('User mean RMSE : {}'.format(user_mean_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computer a test prediction for blending\n",
    "blend_UserMean = compute_user_means(test)\n",
    "# blend_UserMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Item Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 31.795614004135132 seconds ---\n",
      "Item mean RMSE : 1.0938352842783858\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "item_mean_rmse = item_mean_test(ratings, min_num_ratings=10)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('Item mean RMSE : {}'.format(item_mean_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computer a test prediction for blending\n",
    "blend_ItemMean = compute_item_means(test)\n",
    "# blend_ItemMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Matrix Facrization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to tune the hyper-parameters for matrix factorisation with SGD, a k-fold cross validation is used, with $k$ set to be 5. By using grid search, the item penalisation coefficient $\\lambda_{it} = 0.25$, the user penalisation coefficient $\\lambda_{us} = 0.01$, the latent variable $k=20$. This process of SGD is iterated by 50 times, when the change between iterations are small enough to be ignored. The running time of this method is 2067s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning the matrix factorization using SGD...\n",
      "Final RMSE on train data: 0.9912955138845942\n",
      "Final RMSE on test data: 1.0001463113122229.\n",
      "--- 2067.5607390403748 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9912955138845942, 1.0001463113122229)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train_rmse, test_rmse, _, _ = matrix_factorization_sgd(train, test, gamma=0.012, verbose=True, \n",
    "                                                       lambda_user=0.01, lambda_item=0.25,\n",
    "                                                       num_epochs=50, num_features=20)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "train_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same idea as SGD, matrix factorisation with ALS is tuned by using grid search as well. After setting $k=20$, which is found at the initial cursory grid search, it is observed that most results of ALS are better than SGD. Hence, its parameter optimisation is investigated more precisely with a finer grid in grid search. below shows the grid search plot, where the brightest area indicates the most precise prediction. The best-tuned model found turns out to have the item penalisation coefficient $\\lambda_{it} = 0.575$, the user penalisation coefficient $\\lambda_{us} = 0.014$. The model is trained such that the change of improvement between each iteration is neglectable ($10^{-6}$). The running time of this method is 1847s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning the matrix factorization using ALS...\n",
      "Final RMSE on train data: 0.9082974241119364\n",
      "Final RMSE on test data: 0.983983639\n",
      "--- 1847.3403561115265 seconds ---\n",
      "0.9082974241119364 0.983983639\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train_rmse, test_rmse, _, _ = matrix_factorization_als(train, test, verbose=True, stop_criterion=0.00001,\n",
    "                                                       lambda_user=0.14, lambda_item=0.575, num_features=20)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(train_rmse, test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. NNMF section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Neural network matrix factorization` or NNMF, for short—dominates standard low-rank techniques on a suite of benchmark but is dominated by some recent proposals that take advantage of the graph features. Given the vast range of architectures, activation functions, regularizers, and optimizationtechniques that could be used within the NNMF framework, it seems likely the true potential of the approach has yet to be reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is presented by Gintare Karolina Dziugaite.The neural network contains three layers with 50 units. \n",
    "After tuning hyper-parameter, we set lamda=1.4841, D=40, D_prim=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import nnmf.nnmf \n",
    "import nnmf.predict\n",
    "import nnmf.split_data  \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data\n",
      "number of items: 10000, number of users: 1000\n",
      "Data subsets:\n",
      "Train: 953330\n",
      "Validation: 105926\n",
      "Test: 117696\n"
     ]
    }
   ],
   "source": [
    "#split train and test set by our defaut setting\n",
    "nnmf.split_data.split_nnmf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network & initializing variables\n",
      "Reading in data\n",
      "[start] Train error: 95769.312500, Train RMSE: 1.823475; Valid RMSE: 1.820590\n",
      "Early stopping (0.9900772571563721 vs. 0.9904701709747314)...\n",
      "Loading best checkpointed model\n",
      "./model/nnmf.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./model/nnmf.ckpt\n",
      "Final train RMSE: 0.958625078201294\n",
      "Final test RMSE: 0.9892654418945312\n"
     ]
    }
   ],
   "source": [
    "#training nnmf (test_ratio=0.1)\n",
    "#if you want to see the process, set verbose=True\n",
    "nnmf.nnmf.do_nnmf(mode='train', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN is a prediction algorithm that computes a prediction for the rating exploiting a weighted sum of the other users/items ratings with the help of a similarity metric, in our case Pearson Baseline. This algorithm implemented in the Python Surprise library. min_k (int) – The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the prediction is set the the global mean of all ratings. Default is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import KNNBasic\n",
    "import os\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and set train and test in surprise library\n",
    "file_path_train = os.path.expanduser('./data/mov_kaggle.all')\n",
    "reader = Reader(line_format='user item rating', sep='\\t')\n",
    "data = Dataset.load_from_file(file_path_train, reader=reader)\n",
    "trainset, testset = train_test_split(data, test_size=.1)   #test ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.019656231639403"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name': 'msd',\n",
    "               'user_based': True  # compute  similarities between items\n",
    "               }\n",
    "algo = KNNBasic(k = 80, sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0234965094325155"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name': 'msd',\n",
    "               'user_based': False  # compute  similarities between users\n",
    "               }\n",
    "algo = KNNBasic(k = 20, sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
