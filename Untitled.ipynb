{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-bc07897f56fe>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-bc07897f56fe>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    from blending(1).py import *\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from blending(1).py import *\n",
    "from helpers import load_data\n",
    "from utils import get_indices\n",
    "import nnmf.split_data\n",
    "from matrix_factorization import *\n",
    "\n",
    "def mf_pred(user_features, item_features, input_path,\n",
    "                          verbose=False):\n",
    "    nnz_train = np.array(pd.read_csv(input_path, sep='\\t', header=None,))\n",
    "    mf = []\n",
    "    for i, k in enumerate(nnz_train):\n",
    "        item = int(k[0])-1\n",
    "        user = int(k[1])-1\n",
    "        mf.append( user_features[:, user].T.dot(item_features[:, item]))\n",
    "    return mf\n",
    "\n",
    "\n",
    "# load training set\n",
    "print('Loading training set')\n",
    "train = load_data('./data/data_train.csv')\n",
    "nnz_train = get_indices(train)\n",
    "path_dataset = \"./data/data_train.csv\"\n",
    "ratings = load_data(path_dataset)\n",
    "\n",
    "from \n",
    "_, train, test = split_data(ratings, 10, verbose=True)\n",
    "with open('../data/pickle/train.pickle', 'wb') as file:\n",
    "    pickle.dump(train, file)\n",
    "with open('../data/pickle/test.pickle', 'wb') as file:\n",
    "    pickle.dump(test, file)\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "After some tests, the best score is achieved by only blending the als predictions (that means dilating them).\n",
    "Another good performance was achieved by blending ALS, user-based  and item based collaborative filtering. Details about \n",
    "the tests can be found in the notebook 'src/notebook/blending.ipynb'.\n",
    "\"\"\"\n",
    "\n",
    "# Train the model (actually if the files are present, nothing is done.\n",
    "print('Training the model')\n",
    "_, user_features, item_features = matrix_factorization_als(ratings, None, verbose=True, stop_criterion=0.00001,\n",
    "                                                           lambda_user=0.014, lambda_item=0.575,\n",
    "                                                           num_features=20)\n",
    "write_als_prediction(user_features, item_features)\n",
    "\n",
    "\n",
    "als_predictions = nnmf.split_data.load_data2('./data/predictions/als_prediction.csv')\n",
    "\n",
    "# Train the blending with Ridge Regression\n",
    "# print('Training the blending with ridge regression')\n",
    "alpha = 0.1\n",
    "re_als = als_pred(user_features, item_features, input_path='../data/mov_kaggle.all' )\n",
    "label = pd.read_csv('./data/mov_kaggle.all', sep='\\t', header=None).iloc[:,2]\n",
    "w, rm= blend_train(als = np.array(re_als).reshape((len(re_als),1)), alpha=0.1, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1176952 stored elements in LInked List format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set\n",
      "Training the model\n",
      "Files are not present, training the model now.\n",
      "Learning the matrix factorization using ALS...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'../data/pickle/data_train_als.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-eb920160b61d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Train the model (actually if the files are present, nothing is done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training the model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrain_als\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Load trained model and predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/submit1/submit/blending.py\u001b[0m in \u001b[0;36mtrain_als\u001b[0;34m(ratings)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mals_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'../data/pickle/data_train_als.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlil_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mals_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'../data/pickle/data_train_als.pickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from blending import *\n",
    "from helpers import load_data\n",
    "from utils import get_indices\n",
    "\n",
    "# load training set\n",
    "print('Loading training set')\n",
    "train = load_data('./data/data_train.csv')\n",
    "nnz_train = get_indices(train)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "After some tests, the best score is achieved by only blending the als predictions (that means dilating them).\n",
    "Another good performance was achieved by blending ALS, user-based  and item based collaborative filtering. Details about \n",
    "the tests can be found in the notebook 'src/notebook/blending.ipynb'.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "methods = ['als']\n",
    "\n",
    "# Train the model (actually if the files are present, nothing is done.\n",
    "print('Training the model')\n",
    "train_als(train)\n",
    "\n",
    "# Load trained model and predictions\n",
    "print('Now loading the pre trained model')\n",
    "with open(b'./data/pickle/data_train_als.pickle', 'rb') as f:\n",
    "    als_train = pickle.load(f)\n",
    "als_predictions = load_data('./data/predictions/als_prediction.csv')\n",
    "\n",
    "nnz_sub = get_indices(als_predictions)\n",
    "\n",
    "# Train the blending with Ridge Regression\n",
    "print('Training the blending with ridge regression')\n",
    "alpha = 0.1\n",
    "m_train, y_train = build_matrix(nnz_train, methods, train, None, None, None, None, als_train, None, None, predict=False)\n",
    "w = np.linalg.solve(m_train.T.dot(m_train) + alpha * np.eye(m_train.shape[1]), m_train.T.dot(y_train))\n",
    "print('Dilatation coefficient (single ridge coefficient) : ')\n",
    "print(w)\n",
    "\n",
    "# Compute training RMSE\n",
    "print('Train RMSE : {}'.format(np.sqrt(np.mean((y_train - m_train.dot(w)) ** 2))))\n",
    "\n",
    "\n",
    "# Apply weight vector to final predictions (and not to training ratings anymore)\n",
    "print('Blending the predictions')\n",
    "m_sub, _ = build_matrix(nnz_sub, methods, None, None, None, None, None, als_predictions, None, None, predict=True)\n",
    "y_predict_sub = m_sub.dot(w)\n",
    "\n",
    "for i in range(len(y_predict_sub)):\n",
    "    y_predict_sub[i] = min(5, max(1, y_predict_sub[i]))\n",
    "\n",
    "# Write prediction to file\n",
    "path = './data/predictions/blended_prediction.csv'\n",
    "print(\"Writing prediction to file : '{}'\".format(path))\n",
    "with open(path, 'w') as output:\n",
    "    output.write('Id,Prediction\\n')\n",
    "    for i, (row, col) in enumerate(nnz_sub):\n",
    "        output.write('r{}_c{},{}\\n'.format(row + 1, col + 1, y_predict_sub[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
